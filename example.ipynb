{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio\n",
    "!pip install SuperSuit==3.4.0\n",
    "!pip install ray[rllib]==0.8.5\n",
    "!pip install lz4\n",
    "!pip install opencv-python==4.5.5.64\n",
    "!pip install dm_tree\n",
    "!pip install stable-baselines3\n",
    "!pip install pettingzoo==1.18.1\n",
    "!pip install sb3-contrib\n",
    "!pip install gym==0.23.1\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from social_dilemmas.envs.pettingzoo_env import MAX_CYCLES\n",
    "from social_dilemmas.envs.pettingzoo_env import env as aec_env\n",
    "from social_dilemmas.envs.pettingzoo_env import parallel_env\n",
    "from pettingzoo.test import parallel_api_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, img, cummulative_reward, step=0, info=\"\", outer_step=0, save=False, path='pictures/near/'):\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d | Reward: %r\" % (env.metadata['name'],step, cummulative_reward))\n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    if save:\n",
    "        name_to_save = path+'step_'+str(outer_step)+'_'+str(step)+'.png'\n",
    "        plt.savefig(name_to_save)\n",
    "        env.render(mode='rgb_array')\n",
    "        return name_to_save\n",
    "    else:\n",
    "        env.render(mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from random import randint\n",
    "\n",
    "\n",
    "env = aec_env(env = \"harvest\", num_agents = 2, proportion=0.5)\n",
    "env.reset()\n",
    "n_act = env.action_space(env.agents[0]).n\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "counter = 0\n",
    "cummulative_reward = 0\n",
    "for agent in env.agent_iter(200):\n",
    "    counter += 1\n",
    "    obs, reward, done, info = env.last()        \n",
    "    cummulative_reward += reward\n",
    "    action = randint(0,n_act-1) if not done else None\n",
    "    env.step(action)\n",
    "    show_state(env, img, cummulative_reward, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in env.agent_iter(MAX_CYCLES * env.num_agents):\n",
    "    _,_,done,_ = env.last()\n",
    "    action = randint(0,n_act-1) if not done else None\n",
    "    env.step(action)\n",
    "    if not env.agents:\n",
    "        env.reset()\n",
    "# api_test(env, MAX_CYCLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = parallel_env(max_cycles=MAX_CYCLES, env = \"harvest\", num_agents = 2, proportion=.5)\n",
    "env.reset()\n",
    "n_act = env.action_space(env.agents[0]).n\n",
    "for _ in range(MAX_CYCLES * env.num_agents):\n",
    "    actions = {agent: np.random.randint(n_act) for agent in env.agents}\n",
    "    _, _, _, _ = env.step(actions)\n",
    "    if not env.agents:\n",
    "        _ = env.reset()\n",
    "parallel_api_test(env, MAX_CYCLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.dqn import CnnPolicy, MlpPolicy\n",
    "# from stable_baselines3.a2c import CnnPolicy, MlpPolicy\n",
    "# from sb3_contrib.trpo import CnnPolicy, MlpPolicy\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from sb3_contrib import TRPO\n",
    "import supersuit as ss\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import VecMonitor\n",
    "\n",
    "num_agents = 2\n",
    "number_of_envs = 16\n",
    "num_cpus=8\n",
    "\n",
    "env = parallel_env(max_cycles=MAX_CYCLES, env = \"harvest\", num_agents = num_agents, proportion=.5)\n",
    "\n",
    "# env = ss.color_reduction_v0(env, mode=\"full\")\n",
    "env = ss.resize_v1(env, x_size=36, y_size=36, linear_interp=False)\n",
    "env = ss.frame_stack_v1(env, 1)\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "\n",
    "env = ss.concat_vec_envs_v1(env, number_of_envs, num_cpus=num_cpus, base_class=\"stable_baselines3\")\n",
    "env = VecMonitor(env, info_keywords=('Utilitarian',), filename='logs/')\n",
    "\n",
    "# model = PPO(\n",
    "#     CnnPolicy,\n",
    "#     env,\n",
    "#     verbose=3,\n",
    "#     gamma=.97,\n",
    "#     tensorboard_log=\"runs/A2C\")\n",
    "\n",
    "model = DQN( \n",
    "    CnnPolicy,\n",
    "    env,\n",
    "    gamma=0.97,\n",
    "    verbose=3,\n",
    "    tensorboard_log=\"runs/POC_DQN\")\n",
    "# model = A2C(\n",
    "#     CnnPolicy,\n",
    "#     env,\n",
    "#     gamma= .95,\n",
    "    # ent_coef= 1.0558813779064815e-05,\n",
    "    # learning_rate= 0.00037520558551242813,\n",
    "    # vf_coef= 0.2912291401980419,\n",
    "#     verbose=3,\n",
    "#     tensorboard_log=\"runs/Real_POC_A2C\")\n",
    "# model = TRPO(\n",
    "#     CnnPolicy,\n",
    "#     env,\n",
    "    # gamma= .95,\n",
    "    # ent_coef= 1.0558813779064815e-05,\n",
    "    # learning_rate= 0.00037520558551242813,\n",
    "    # vf_coef= 0.2912291401980419,\n",
    "#     verbose=3,\n",
    "#     tensorboard_log=\"runs/Real_POC_TRPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    name=\"Real_POC_A2C\",\n",
    "    project=\"sb3\",\n",
    "    config={\"policy_type\": \"CNNPolicy\", \"total_timesteps\": 1_500_000},\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    monitor_gym=False,  # auto-upload the videos of agents playing the game\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "class UtilitarianCallBack(WandbCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(UtilitarianCallBack, self).__init__(verbose)\n",
    "    def _on_training_start(self):\n",
    "        self._log_freq = 500  # log every 200 calls\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self._log_freq == 0:\n",
    "            counter = 0\n",
    "            uti = sum(item['Utilitarian'] for item in self.locals['infos'])/(number_of_envs*num_agents) # <- number of env running at the same time, number of agents\n",
    "            eq = sum(item['Equality'] for item in self.locals['infos'])/(number_of_envs*num_agents)\n",
    "            # sus = sum(item['Sustainability'] for item in self.locals['infos'])/(number_of_envs*num_agents)\n",
    "            agent_1 = []\n",
    "            agent_2 = []\n",
    "            for numb in range(number_of_envs*num_agents):\n",
    "                if numb%2==0:\n",
    "                    agent_1.append(sum(self.locals['infos'][numb]['Reward']))\n",
    "                else:\n",
    "                    agent_2.append(sum(self.locals['infos'][numb]['Reward']))\n",
    "                    \n",
    "            self.logger.record('custom/utilitarian', uti)\n",
    "            self.logger.record('custom/equality', eq)\n",
    "            self.logger.record('custom/reward_agent_1', np.mean(agent_1))\n",
    "            self.logger.record('custom/reward_agent_2', np.mean(agent_2))\n",
    "            # self.logger.record('custom/sustainability', sus)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/envs/social/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1617/2648240314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msb3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWandbCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.learn(total_timesteps=1000000,     \n\u001b[0m\u001b[1;32m      4\u001b[0m             callback=WandbCallback(\n\u001b[1;32m      5\u001b[0m             \u001b[0mgradient_save_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=1_500_000,     \n",
    "            callback=UtilitarianCallBack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def save_frames_as_gif(frames, path='./', filename='gym_animation.gif'):\n",
    "    #Mess with this to change frame size\n",
    "    plt.figure(figsize=(frames[0].shape[1], frames[0].shape[0]))\n",
    "\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    anim.save(path + filename, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=100)\n",
    "\n",
    "print(mean_reward, std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from random import randint\n",
    "\n",
    "env = aec_env(env = \"harvest\", num_agents = 2, proportion=.5)\n",
    "# env = ss.color_reduction_v0(env, mode=\"full\")\n",
    "env = ss.resize_v1(env, x_size=36, y_size=36, linear_interp=False)\n",
    "env = ss.frame_stack_v1(env, 1)\n",
    "\n",
    "# model = A2C.load(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "name_frames = []\n",
    "\n",
    "outer_counter=0\n",
    "\n",
    "for i in range(10):\n",
    "    outer_counter += 1\n",
    "    env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    counter = 0\n",
    "    cummulative_reward = 0\n",
    "    for agent in env.agent_iter(100):\n",
    "        counter += 1\n",
    "        obs, reward, done, info = env.last()\n",
    "        cummulative_reward += reward\n",
    "        action = model.predict(obs, deterministic=True)[0] if not done else None\n",
    "        env.step(action)\n",
    "        name_frames.append(show_state(env, img, round(cummulative_reward, 3), counter, outer_step=outer_counter\n",
    "        #                               , save=True, path='pictures/far/'\n",
    "                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "with imageio.get_writer('far.gif', mode='I') as writer:\n",
    "    for filename in name_frames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c54f4e1905cd32010bf341b03818db875e58910116369b81e2031cacd9a8002"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('social')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c54f4e1905cd32010bf341b03818db875e58910116369b81e2031cacd9a8002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
