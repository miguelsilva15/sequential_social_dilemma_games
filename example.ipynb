{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio\n",
    "!pip install SuperSuit==3.4.0\n",
    "!pip install ray[rllib]==0.8.5\n",
    "!pip install lz4\n",
    "!pip install opencv-python==4.5.5.64\n",
    "!pip install dm_tree\n",
    "!pip install stable-baselines3\n",
    "!pip install pettingzoo==1.18.1\n",
    "!pip install sb3-contrib\n",
    "!pip install gym==0.23.1\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from social_dilemmas.envs.pettingzoo_env import MAX_CYCLES\n",
    "from social_dilemmas.envs.pettingzoo_env import env as aec_env\n",
    "from social_dilemmas.envs.pettingzoo_env import parallel_env\n",
    "from pettingzoo.test import parallel_api_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, img, cummulative_reward, step=0, info=\"\", outer_step=0, save=False, path='pictures/near/'):\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d | Reward: %r\" % (env.metadata['name'],step, cummulative_reward))\n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    if save:\n",
    "        name_to_save = path+'step_'+str(outer_step)+'_'+str(step)+'.png'\n",
    "        plt.savefig(name_to_save)\n",
    "        env.render(mode='rgb_array')\n",
    "        return name_to_save\n",
    "    else:\n",
    "        env.render(mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from random import randint\n",
    "\n",
    "\n",
    "env = aec_env(env = \"harvest\", num_agents = 2, proportion=0.5)\n",
    "env.reset()\n",
    "n_act = env.action_space(env.agents[0]).n\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "counter = 0\n",
    "cummulative_reward = 0\n",
    "for agent in env.agent_iter(10):\n",
    "    counter += 1\n",
    "    obs, reward, done, info = env.last()        \n",
    "    cummulative_reward += reward\n",
    "    action = randint(0,n_act-1) if not done else None\n",
    "    obss = obs.copy()\n",
    "    r = env.step(action)\n",
    "    show_state(env, img, round(cummulative_reward, 2), counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in env.agent_iter(MAX_CYCLES * env.num_agents):\n",
    "    _,_,done,_ = env.last()\n",
    "    action = randint(0,n_act-1) if not done else None\n",
    "    env.step(action)\n",
    "    if not env.agents:\n",
    "        env.reset()\n",
    "# api_test(env, MAX_CYCLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = parallel_env(max_cycles=MAX_CYCLES, env = \"harvest\", num_agents = 2, proportion=.5)\n",
    "env.reset()\n",
    "n_act = env.action_space(env.agents[0]).n\n",
    "for _ in range(MAX_CYCLES * env.num_agents):\n",
    "    actions = {agent: np.random.randint(n_act) for agent in env.agents}\n",
    "    _, _, _, _ = env.step(actions)\n",
    "    if not env.agents:\n",
    "        _ = env.reset()\n",
    "parallel_api_test(env, MAX_CYCLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.dqn import CnnPolicy, MlpPolicy\n",
    "from stable_baselines3.a2c import CnnPolicy, MlpPolicy\n",
    "# from sb3_contrib.trpo import CnnPolicy, MlpPolicy\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from sb3_contrib import TRPO\n",
    "import supersuit as ss\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import VecMonitor\n",
    "\n",
    "num_agents = 2\n",
    "number_of_envs = 16\n",
    "num_cpus=8\n",
    "\n",
    "env = parallel_env(max_cycles=MAX_CYCLES, env = \"harvest\", num_agents = num_agents, proportion=.5)\n",
    "\n",
    "# env = ss.color_reduction_v0(env, mode=\"full\")\n",
    "env = ss.resize_v1(env, x_size=36, y_size=36, linear_interp=False)\n",
    "env = ss.frame_stack_v1(env, 1)\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "\n",
    "env = ss.concat_vec_envs_v1(env, number_of_envs, num_cpus=num_cpus, base_class=\"stable_baselines3\")\n",
    "env = VecMonitor(env, info_keywords=('Utilitarian',), filename='logs/')\n",
    "\n",
    "# model = PPO(\n",
    "#     CnnPolicy,\n",
    "#     env,\n",
    "#     verbose=3,\n",
    "#     gamma=.97,\n",
    "#     tensorboard_log=\"runs/A2C\")\n",
    "\n",
    "# model = DQN( \n",
    "#     CnnPolicy,\n",
    "#     env,\n",
    "#     gamma= .95,\n",
    "#     verbose=3,\n",
    "#     exploration_fraction=0.25,\n",
    "#     exploration_final_eps=0.1,\n",
    "#     tensorboard_log=\"runs/Battle_DQN\")\n",
    "model = A2C(\n",
    "    CnnPolicy,\n",
    "    env,\n",
    "    gamma= .98,\n",
    "    ent_coef= 1.6835848102390265e-05,\n",
    "    use_rms_prop= True,\n",
    "    learning_rate= 0.0005932893977209943,\n",
    "    max_grad_norm= 0.8,\n",
    "    vf_coef= 0.47382346265030867,\n",
    "    verbose=3,\n",
    "    tensorboard_log=\"runs/A2C_Fixed_Distance\")\n",
    "# model = TRPO(\n",
    "#     CnnPolicy,\n",
    "#     env,\n",
    "    # gamma= .95,\n",
    "    # ent_coef= 1.0558813779064815e-05,\n",
    "    # learning_rate= 0.0005932893977209943,\n",
    "    # vf_coef= 0.2912291401980419,\n",
    "#     verbose=3,\n",
    "#     tensorboard_log=\"runs/Real_POC_TRPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    name=\"A2C_Fixed_Distance\",\n",
    "    project=\"sb3\",\n",
    "    config={\"policy_type\": \"CNNPolicy\", \"total_timesteps\": 2_000_000},\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    monitor_gym=False,  # auto-upload the videos of agents playing the game\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "class UtilitarianCallBack(WandbCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(UtilitarianCallBack, self).__init__(verbose)\n",
    "    def _on_training_start(self):\n",
    "        self._log_freq = 500  # log every 200 calls\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self._log_freq == 0:\n",
    "            counter = 0\n",
    "            uti = sum(item['Utilitarian'] for item in self.locals['infos'])/(number_of_envs*num_agents) # <- number of env running at the same time, number of agents\n",
    "            eq = sum(item['Equality'] for item in self.locals['infos'])/(number_of_envs*num_agents)\n",
    "            # sus = sum(item['Sustainability'] for item in self.locals['infos'])/(number_of_envs*num_agents)\n",
    "            agent_1 = []\n",
    "            agent_2 = []\n",
    "            for numb in range(number_of_envs*num_agents):\n",
    "                if numb%2==0:\n",
    "                    agent_1.append(sum(self.locals['infos'][numb]['Reward']))\n",
    "                else:\n",
    "                    agent_2.append(sum(self.locals['infos'][numb]['Reward']))\n",
    "                    \n",
    "            self.logger.record('custom/utilitarian', uti)\n",
    "            self.logger.record('custom/equality', eq)\n",
    "            self.logger.record('custom/reward_agent_1', np.mean(agent_1))\n",
    "            self.logger.record('custom/reward_agent_2', np.mean(agent_2))\n",
    "            # self.logger.record('custom/sustainability', sus)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/envs/social/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1617/2648240314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msb3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWandbCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.learn(total_timesteps=1000000,     \n\u001b[0m\u001b[1;32m      4\u001b[0m             callback=WandbCallback(\n\u001b[1;32m      5\u001b[0m             \u001b[0mgradient_save_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=2_000_000,     \n",
    "            callback=UtilitarianCallBack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def save_frames_as_gif(frames, path='./', filename='gym_animation.gif'):\n",
    "    #Mess with this to change frame size\n",
    "    plt.figure(figsize=(frames[0].shape[1], frames[0].shape[0]))\n",
    "\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    anim.save(path + filename, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=100)\n",
    "\n",
    "print(mean_reward, std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from random import randint\n",
    "\n",
    "env = aec_env(env = \"harvest\", num_agents = 2, proportion=.5)\n",
    "# env = ss.color_reduction_v0(env, mode=\"full\")\n",
    "env = ss.resize_v1(env, x_size=36, y_size=36, linear_interp=False)\n",
    "env = ss.frame_stack_v1(env, 1)\n",
    "\n",
    "# model = A2C.load(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "name_frames = []\n",
    "\n",
    "outer_counter=0\n",
    "\n",
    "for i in range(10):\n",
    "    outer_counter += 1\n",
    "    env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    counter = 0\n",
    "    cummulative_reward = 0\n",
    "    for agent in env.agent_iter(100):\n",
    "        counter += 1\n",
    "        obs, reward, done, info = env.last()\n",
    "        cummulative_reward += reward\n",
    "        action = model.predict(obs, deterministic=True)[0] if not done else None\n",
    "        env.step(action)\n",
    "        name_frames.append(show_state(env, img, round(cummulative_reward, 3), counter, outer_step=outer_counter\n",
    "        #                               , save=True, path='pictures/far/'\n",
    "                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "with imageio.get_writer('far.gif', mode='I') as writer:\n",
    "    for filename in name_frames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c54f4e1905cd32010bf341b03818db875e58910116369b81e2031cacd9a8002"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('social')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c54f4e1905cd32010bf341b03818db875e58910116369b81e2031cacd9a8002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
